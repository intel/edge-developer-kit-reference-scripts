--- inference_ov_ori.py	2025-07-08 15:26:35.287822879 +0800
+++ inference_ov.py	2025-07-08 15:25:19.705816421 +0800
@@ -1,19 +1,14 @@
 from os import listdir, path
 import numpy as np
-import scipy
 import cv2
 import os
-import sys
 import argparse
-import audio
-import json
+from .audio import load_wav, melspectrogram
 import subprocess
-import random
-import string
 from tqdm import tqdm
 from glob import glob
 import torch
-from models import Wav2Lip
+from .models import Wav2Lip
 import platform
 import openvino as ov
 from pathlib import Path
@@ -30,74 +25,6 @@
     's3fd': 'https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth',
 }
 
-parser = argparse.ArgumentParser(
-    description='Inference code to lip-sync videos in the wild using Wav2Lip models')
-
-parser.add_argument('--face_detection_path', type=str,
-                    help='Path to face detection openvino model path ', required=True)
-parser.add_argument('--wav2lip_path', type=str,
-                    help='Path to wav2lip openvino model path ', required=True)
-parser.add_argument('--inference_device', type=str,
-                    help='Specify OpenVINO inference device', default="CPU", required=True)
-parser.add_argument('--face', type=str,
-                    help='Filepath of video/image that contains faces to use', required=True)
-parser.add_argument('--audio', type=str,
-                    help='Filepath of video/audio file to use as raw audio source', required=True)
-parser.add_argument('--outfile', type=str, help='Video path to save result. See default for an e.g.',
-                    default='results/result_voice.mp4')
-
-parser.add_argument('--static', type=bool,
-                    help='If True, then use only first video frame for inference', default=False)
-parser.add_argument('--fps', type=float, help='Can be specified only if input is a static image (default: 25)',
-                    default=25., required=False)
-
-parser.add_argument('--pads', nargs='+', type=int, default=[0, 10, 0, 0],
-                    help='Padding (top, bottom, left, right). Please adjust to include chin at least')
-
-parser.add_argument('--face_det_batch_size', type=int,
-                    help='Batch size for face detection', default=16)
-parser.add_argument('--wav2lip_batch_size', type=int,
-                    help='Batch size for Wav2Lip model(s)', default=128)
-
-parser.add_argument('--resize_factor', default=1, type=int,
-                    help='Reduce the resolution by this factor. Sometimes, best results are obtained at 480p or 720p')
-
-parser.add_argument('--crop', nargs='+', type=int, default=[0, -1, 0, -1],
-                    help='Crop video to a smaller region (top, bottom, left, right). Applied after resize_factor and rotate arg. '
-                    'Useful if multiple face present. -1 implies the value will be auto-inferred based on height, width')
-
-parser.add_argument('--box', nargs='+', type=int, default=[-1, -1, -1, -1],
-                    help='Specify a constant bounding box for the face. Use only as a last resort if the face is not detected.'
-                    'Also, might work only if the face is not moving around much. Syntax: (top, bottom, left, right).')
-
-parser.add_argument('--rotate', default=False, action='store_true',
-                    help='Sometimes videos taken from a phone can be flipped 90deg. If true, will flip video right by 90deg.'
-                    'Use if you get a flipped result, despite feeding a normal looking video')
-
-parser.add_argument('--nosmooth', default=False, action='store_true',
-                    help='Prevent smoothing face detections over a short temporal window')
-
-args = parser.parse_args()
-args.img_size = 96
-
-if os.path.isfile(args.face) and args.face.split('.')[1] in ['jpg', 'png', 'jpeg']:
-    args.static = True
-try:
-    from iou import IOU
-except BaseException:
-    # IOU cython speedup 10x
-    def IOU(ax1, ay1, ax2, ay2, bx1, by1, bx2, by2):
-        sa = abs((ax2 - ax1) * (ay2 - ay1))
-        sb = abs((bx2 - bx1) * (by2 - by1))
-        x1, y1 = max(ax1, bx1), max(ay1, by1)
-        x2, y2 = min(ax2, bx2), min(ay2, by2)
-        w = x2 - x1
-        h = y2 - y1
-        if w < 0 or h < 0:
-            return 0.0
-        else:
-            return 1.0 * w * h / (sa + sb - w * h)
-
 
 def bboxlog(x1, y1, x2, y2, axc, ayc, aww, ahh):
     xc, yc, ww, hh = (x2 + x1) / 2, (y2 + y1) / 2, x2 - x1, y2 - y1
@@ -281,7 +208,7 @@
     BB, CC, HH, WW = imgs.size()
 
     results = net({"x": imgs.numpy()})
-    olist = [torch.Tensor(results[i]) for i in range(12)]
+    olist = [torch.Tensor(results[i]) for i in racom(12)]
     bboxlist = []
     for i in range(len(olist) // 2):
         olist[i * 2] = F.softmax(olist[i * 2], dim=1)
@@ -694,8 +621,8 @@
         subprocess.call(command, shell=True)
         args.audio = 'temp/temp.wav'
 
-    wav = audio.load_wav(args.audio, 16000)
-    mel = audio.melspectrogram(wav)
+    wav = load_wav(args.audio, 16000)
+    mel = melspectrogram(wav)
     print(mel.shape)
 
     if np.isnan(mel.reshape(-1)).sum() > 0:
@@ -752,5 +679,77 @@
     subprocess.call(command, shell=platform.system() != 'Windows')
 
 
+def combine_audio_with_generated_video(audio_path, output_path):
+    command = 'ffmpeg -y -i {} -i {} -strict -2 -q:v 1 -vf "hqdn3d,unsharp=5:5:0.5" {} > /dev/null 2>&1'.format(
+            audio_path, 'wav2lip/temp/result.avi', output_path)
+    subprocess.call(command, shell=platform.system() != 'Windows')
+
 if __name__ == '__main__':
     main()
+    parser = argparse.ArgumentParser(
+        description='Inference code to lip-sync videos in the wild using Wav2Lip models')
+
+    parser.add_argument('--face_detection_path', type=str,
+                        help='Path to face detection openvino model path ', required=True)
+    parser.add_argument('--wav2lip_path', type=str,
+                        help='Path to wav2lip openvino model path ', required=True)
+    parser.add_argument('--inference_device', type=str,
+                        help='Specify OpenVINO inference device', default="CPU", required=True)
+    parser.add_argument('--face', type=str,
+                        help='Filepath of video/image that contains faces to use', required=True)
+    parser.add_argument('--audio', type=str,
+                        help='Filepath of video/audio file to use as raw audio source', required=True)
+    parser.add_argument('--outfile', type=str, help='Video path to save result. See default for an e.g.',
+                        default='results/result_voice.mp4')
+
+    parser.add_argument('--static', type=bool,
+                        help='If True, then use only first video frame for inference', default=False)
+    parser.add_argument('--fps', type=float, help='Can be specified only if input is a static image (default: 25)',
+                        default=25., required=False)
+
+    parser.add_argument('--pads', nargs='+', type=int, default=[0, 10, 0, 0],
+                        help='Padding (top, bottom, left, right). Please adjust to include chin at least')
+
+    parser.add_argument('--face_det_batch_size', type=int,
+                        help='Batch size for face detection', default=16)
+    parser.add_argument('--wav2lip_batch_size', type=int,
+                        help='Batch size for Wav2Lip model(s)', default=128)
+
+    parser.add_argument('--resize_factor', default=1, type=int,
+                        help='Reduce the resolution by this factor. Sometimes, best results are obtained at 480p or 720p')
+
+    parser.add_argument('--crop', nargs='+', type=int, default=[0, -1, 0, -1],
+                        help='Crop video to a smaller region (top, bottom, left, right). Applied after resize_factor and rotate arg. '
+                        'Useful if multiple face present. -1 implies the value will be auto-inferred based on height, width')
+
+    parser.add_argument('--box', nargs='+', type=int, default=[-1, -1, -1, -1],
+                        help='Specify a constant bounding box for the face. Use only as a last resort if the face is not detected.'
+                        'Also, might work only if the face is not moving around much. Syntax: (top, bottom, left, right).')
+
+    parser.add_argument('--rotate', default=False, action='store_true',
+                        help='Sometimes videos taken from a phone can be flipped 90deg. If true, will flip video right by 90deg.'
+                        'Use if you get a flipped result, despite feeding a normal looking video')
+
+    parser.add_argument('--nosmooth', default=False, action='store_true',
+                        help='Prevent smoothing face detections over a short temporal window')
+
+    args = parser.parse_args()
+    args.img_size = 96
+
+    if os.path.isfile(args.face) and args.face.split('.')[1] in ['jpg', 'png', 'jpeg']:
+        args.static = True
+    try:
+        from iou import IOU
+    except BaseException:
+        # IOU cython speedup 10x
+        def IOU(ax1, ay1, ax2, ay2, bx1, by1, bx2, by2):
+            sa = abs((ax2 - ax1) * (ay2 - ay1))
+            sb = abs((bx2 - bx1) * (by2 - by1))
+            x1, y1 = max(ax1, bx1), max(ay1, by1)
+            x2, y2 = min(ax2, bx2), min(ay2, by2)
+            w = x2 - x1
+            h = y2 - y1
+            if w < 0 or h < 0:
+                return 0.0
+            else:
+                return 1.0 * w * h / (sa + sb - w * h)
