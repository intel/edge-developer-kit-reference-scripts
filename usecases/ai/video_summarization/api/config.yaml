# Path to all videos
videos: video_ingest/videos/
# Do you want to extract frames of videos (True if not done already, else False)
generate_frames: True
# How do you want to generate feature embeddings?
embeddings:
  type: 'video' # ['video', 'frame']
  path: 'video_ingest/embeddings'
# VL-branch config
vl_branch:
  cfg_path: embedding/video_llama_config/video_llama_eval_only_vl.yaml
  model_type: 'llama_v2'
# Path to store metadata files
meta_output_dir: video_ingest/video_metadata/
# Chunk duration defines the interval of time that each embedding will occur
chunk_duration: 30
# Clip duration defines the length of the interval in which the embeding will occur
clip_duration: 10
# e.g. For every <chunk_duration>, you embed the first <clip_duration>'s frames of that interval

vector_db:
  choice_of_db: 'vdms' # #Supported databases [vdms]
  host: 0.0.0.0
  port: 55555 

meanclip_cfg_path: embedding/meanclip_config/clip_meanAgg.json

# LVM path
model_path: openbmb/MiniCPM-V-2_6
system_prompt: "You are an AI assistant specializes in monitoring live or recorded security camera footage, identifying suspicious behaviors or actions that could indicate a theft attempt, and then alerting users in real-time with potential theft situations."

#meta-llama/Llama-2-7b-chat-hf

