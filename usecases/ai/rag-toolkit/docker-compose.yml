services:
  ui:
    build:
      context: ./edge-ui
      dockerfile: Dockerfile
    image: edge-ai-tuning-kit.deployment.ui
    container_name: edge-ai-tuning-kit.deployment.ui
    hostname: ui
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - app-network
    ports:
      - "8010:3000"

  backend:
    build:
      context: .
      dockerfile: ./backend/Dockerfile
    image: edge-ai-tuning-kit.deployment.backend
    container_name: edge-ai-tuning-kit.deployment.backend
    hostname: backend
    group_add:
      - ${RENDER_GROUP_ID:-110}
    devices:
      - /dev/dri:/dev/dri
    networks:
      - app-network
    ports:
      - "8011:8011"
    environment:
      - OPENAI_BASE_URL=http://serving:8000/v1
      - EMBEDDING_DEVICE=${EMBEDDING_DEVICE:-CPU}
      - RERANKER_DEVICE=${RERANKER_DEVICE:-CPU}
    depends_on:
      serving:
        condition: service_healthy
      tts_service:
        condition: service_healthy
      stt_service:
        condition: service_healthy
    volumes:
      - ./data:/usr/src/app/data

  serving:
    build:
      context: ../microservices/text-generation/vllm
      dockerfile: Dockerfile
    image: edge-ai-tuning-kit.deployment.serving
    container_name: edge-ai-tuning-kit.deployment.serving
    hostname: serving
    group_add:
      - ${RENDER_GROUP_ID:-110}
    devices:
      - /dev/dri:/dev/dri
    networks:
      - app-network
    environment:
      - DEFAULT_MODEL_ID=Qwen/Qwen2.5-7B-Instruct
      - MODEL_PATH=./data/models/llm
      - MODEL_PRECISION=int4
      - SERVED_MODEL_NAME=ov-vllm
      - MAX_MODEL_LEN=2048
      - MAX_NUM_SEQS=1
      - GPU_MEMORY_UTILIZATION=0.9
      - VLLM_OPENVINO_DEVICE=GPU
      - VLLM_OPENVINO_KVCACHE_SPACE=8
      - VLLM_OPENVINO_CPU_KV_CACHE_PRECISION=u8
      - VLLM_OPENVINO_ENABLE_QUANTIZED_WEIGHTS=ON
    volumes:
      - ./data:/usr/src/app/data
      - ./data/huggingface:/home/intel/.cache/huggingface

  tts_service:
    build:
      context: ../microservices/text-to-speech
      dockerfile: Dockerfile
    image: tts_service
    container_name: edge-ai-tuning-kit.deployment.tts
    hostname: tts_service
    group_add:
      - ${RENDER_GROUP_ID:-110}
    restart: always
    networks:
      - app-network
    environment:
      - TTS_DEVICE=CPU
      - ALLOWED_CORS=["*"]
    ports:
      - 8013:5995
    devices:
      - /dev/dri:/dev/dri
    volumes:
      - ./data/huggingface:/root/.cache/huggingface
      - ./data/nltk_data:/usr/src/app/data/nltk_data

  stt_service:
    build:
      context: ../microservices/speech-to-text
      dockerfile: Dockerfile
    image: stt_service
    container_name: edge-ai-tuning-kit.deployment.stt
    hostname: stt_service
    group_add:
      - ${RENDER_GROUP_ID:-110}
    networks:
      - app-network
    environment:
      - DEFAULT_MODEL_ID=openai/whisper-tiny 
      - STT_DEVICE=CPU
      - ALLOWED_CORS=["*"]
    ports:
      - 8014:5996
    devices:
      - /dev/dri:/dev/dri
    volumes:
      - ./data:/usr/src/app/data:rw

networks:
  app-network:
